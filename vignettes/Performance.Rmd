---
title: "Empirical Performance of Three Circular Data Clustering Algorithms"
author: "Tathagata Debnath and Joe Song"
date: "Updated: 2020-09-05. Created: 2020-08-07"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Empirical Performance of Three Circular Data Clustering Algorithms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---




```{r,  results='hide', message=FALSE, warning=FALSE, echo=FALSE}

library(ggplot2)
library(OptCirClust)
library(knitr)
library(reshape2)

opts_chunk$set(fig.width=6, fig.height=4) 






FOCC <- c()

BOCC <- c()

HEUC <- c()

number <- c()


FOCC_SSQ <- c()

BOCC_SSQ <- c()

HEUC_SSQ <- c()




First <- 1

Prev <- -1

Next <- -1

K <- 3



for(i in seq(10,100, 10 ) )
{


n <- i

set.seed(1)

x <- c(rnorm(n, sd=0.3), rnorm(n, mean=100, sd=0.3), rnorm(n, mean=200, sd=0.3))


Data_Points <- c(x,(x + length(x)))

width <- length(Data_Points)/2

Last <- length(Data_Points) - width 


ptm <- proc.time()

  result1 <- FramedClust(Data_Points,  K, width, First, Last, "linear.polylog")

  time <- proc.time() - ptm

  FOCC <- c(FOCC,as.double(time[3]))







  ptm <- proc.time()

  result2 <- FramedClust(Data_Points,  K, width, First, Last, "Ckmeans.1d.dp")

  time <- proc.time() - ptm

  BOCC <- c(BOCC,as.double(time[3]))





  ptm <- proc.time()

  result3 <- FramedClust(Data_Points,  K, width, First, Last, "kmeans")

  time <- proc.time() - ptm

  HEUC <- c(HEUC,as.double(time[3]))

  


  number <- c(number, n*3)



}



 df1 <- data.frame("No_Points" = number, "FOCC" = FOCC, "BOCC" = BOCC, "HEUC" = HEUC)

 df <- melt(df1, id.var='No_Points')

 plot1 <- ggplot(df, aes(x=No_Points, y=value, col=variable)) + geom_line() + geom_point(alpha=3) +
   labs(y="Runtime (second)", x = "Number of points (N)") +
  labs(colour = "Methods") + 
  scale_y_continuous(trans = 'log2') +
  ylim((min(FOCC,BOCC,HEUC)), (max(FOCC,BOCC,HEUC))) 
 
 
 


FOCC <- c()

BOCC <- c()

HEUC <- c()

clusters <- c()


FOCC_SSQ <- c()

BOCC_SSQ <- c()

HEUC_SSQ <- c()




K <- 3


set.seed(1)

x <- c(rnorm(50, sd=0.3), rnorm(50, mean=100, sd=0.3), rnorm(50, mean=200, sd=0.3))


Data_Points <- c(x,(x + length(x)))

width <- length(Data_Points)/2

Last <- length(Data_Points) - width - 1


for(K in seq(10,100,10))
{

  ptm <- proc.time()

  result1 <- FramedClust(Data_Points,  K, width, First, Last, "linear.polylog")

  time <- proc.time() - ptm

  FOCC <- c(FOCC,as.double(time[3]))

  FOCC_SSQ <- c(FOCC_SSQ,result1$tot.withinss)





  ptm <- proc.time()

  result2 <-  FramedClust(Data_Points,  K, width, First, Last, "Ckmeans.1d.dp")

  time <- proc.time() - ptm

  BOCC <- c(BOCC,as.double(time[3]))

  BOCC_SSQ <- c(BOCC_SSQ,result2$tot.withinss)



  ptm <- proc.time()

  result3 <- FramedClust(Data_Points,  K, width, First, Last, "kmeans")

  time <- proc.time() - ptm

  HEUC <- c(HEUC,as.double(time[3]))

  HEUC_SSQ <- c(HEUC_SSQ,result3$tot.withinss)


  clusters <- c(clusters, K)



}





df1 <- data.frame("No_Clusters" = clusters, "FOCC" = FOCC, "BOCC" = BOCC, "HEUC" = HEUC)

df <- melt(df1, id.var='No_Clusters')

plot2 <- ggplot(df, aes(x=No_Clusters, y=value, col=variable)) + geom_line() + geom_point(alpha=3) +
   labs(y="Runtime (seccond)", x = "Number of clusters (K)") + labs(colour = "Methods") + scale_y_continuous(trans = 'log2')









df1 <- data.frame("No_Clusters" = clusters, "FOCC" = FOCC_SSQ, "BOCC" = BOCC_SSQ, "HEUC" = HEUC_SSQ)

df <- melt(df1, id.var='No_Clusters')

df$mysize <- rep(0, nrow(df))

df$mysize[df$variable=="FOCC"] <- 1
plot3 <- ggplot(df, aes(x=No_Clusters, y=value, col=variable, size=mysize)) + geom_line() + geom_point(alpha=3) +
  labs(y="Within-cluster sum of squared distances", x = "Number of clusters (K)") + labs(colour = "Methods") +
  scale_size(range = c(2, 4), guide="none") + scale_y_continuous(trans = 'log2')



 
 


```

We illustrate the runtime and quality of three circular data clustering algorithms: 1) fast optimal circular clustering (FOCC), 2) heuristic K means clustering (HEUC), and 3) brute force optimal clustering (BOCC).

## Effects of number of points on runtime of circular data clustering  

The runtime of both optimal and heuristic algorithms increases with the number of points in the circular data. Empirical runtime of the three algorithms as a function of the number of points $N$ are shown in the figure below. Both the HEUC and the BOCC algorithms increase at a quadratic rate. In contrast, the runtime of FOCC increases at a linear poly-logarithmic rate. Runtime is crucial for processing large datasets. 

```{r results='hide', message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)

plot(plot1)


```



## Effects of number of clusters on runtime of circular data clustering

The runtime is also affected by the number of clusters $K$ inside the circular data. The figure below shows this effect on the three algorithms. Empirical runtime of both HEUC and BOCC increases at a similar rate to FOCC over an increasing $K$. 

```{r,  results='hide', message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)

plot(plot2)

```



## Effects of number of clusters on quality of circular data clustering

The within-cluster sum of squared distances (SSQ) indicates the compactness of a cluster. A low value of SSQ suggests a good compact clustering outcome. The last figure shows the change in SSQ value with number of clusters $K$ in the data. The SSQ values of BOCC and FOCC always remain no more than that of the HEUC algorithm. This indicates the optimal BOCC and FOCC algorithms identify better clusters than the heuristic HEUC algorithm. The advantage of FOCC and BOCC over HEUC in SSQ gradually increases with $K$. 
```{r,  results='hide', message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)


plot(plot3)

```



## Conclusions

The examples demonstrate the advantage of FOCC algorithm over the existing BOCC and HEUC algorithms in both runtime and cluster quality. Therefore, we recommend FOCC as the best choice for circular clustering; its performance on input circular data consisting of a large number of points, having large number of clusters far exceeds the two alternatives.

